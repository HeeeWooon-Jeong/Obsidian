
# 코드 구현
```python

```


# 라이브러리 설치 및 임포트 코드
```python
pip install -q autoviz
pip install -q -U --pre pycaret
```

# 설치 라이브러리 설명
```


```

```
> pip install -q autoviz
AutoViz"는 데이터를 시각화하고 탐색하는 과정을 자동화하는 Python 패키지입니다. 이 패키지를 사용하면 데이터 집합을 더 잘 이해하기 위한 다양한 시각화를 자동으로 생성할 수 있습니다.



> pip install -q -U --pre pycaret
명령은 Python 환경에서 "PyCaret" 라이브러리를 설치하거나 업그레이드하는 명령입니다. "PyCaret"는 머신 러닝 모델을 구축하고 배포하는 과정을 단순화하는 고수준, 로우코드 머신 러닝 라이브러리로, 데이터와 예측 모델을 다루는 과정을 간단하고 빠르게 만들어줍니다
```

>  '-q' 플래그  설치 프로세스 출력 메시지를 간소화



# 구상

> [!NOTE] 모델
> 텍스트 데이터에 대한 다중 분류 딥러닝 모델을 만들려면 텍스트 데이터를 벡터화하고 자연어 처리(NLP) 모델을 사용해야 합니다.

지도학습(Supervised Learning) 을 통해
"안전한 URL"과 "위험한 URL"에 대한 데이터셋
모델에 상용할 특성은 URL의 길이 도메인이름 경로의 구조 쿼리 파라미터등으로 나눈다

자연어 처리(NLP) 기법을 사용하여 URL 내의 텍스트 정보를 분석









--- 

### hdf5 형태로 최적의 모델 저장 

```python
from tensorflow import keras
from tensorflow.keras.callbacks import ModelCheckpoint

# 모델 생성 및 컴파일
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(784,)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# 모델 체크포인트 콜백 설정
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')

# 모델 훈련
model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val), callbacks=[checkpoint])

```


# 베스트 모델을 불러와서 실행
from tensorflow.keras.models import load_model

best_model = load_model("./폴더명/파일명.hdf5")

best_model.evaluate(X, y)

---
