
### csv읽어오기
```python
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# 모델 정의
class URLClassifier(nn.Module):
    def __init__(self, vocab_size, embedding_dim, num_classes):
        super(URLClassifier, self).__init()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.conv1 = nn.Conv1d(in_channels=embedding_dim, out_channels=128, kernel_size=3)
        self.fc = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.embedding(x)
        x = x.permute(0, 2, 1)  # Conv1D의 입력 형태로 변환
        x = self.conv1(x)
        x = torch.max(x, dim=2)[0]  # Max pooling
        x = self.fc(x)
        return x

# 하이퍼파라미터
vocab_size = 10000  # URL 데이터셋의 어휘 크기에 맞게 설정
embedding_dim = 50
num_classes = 3  # 분류할 URL 유형 수에 맞게 설정
learning_rate = 0.001
num_epochs = 10

# 모델 생성
model = URLClassifier(vocab_size, embedding_dim, num_classes)

# 손실 함수 및 최적화 함수 정의
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# 훈련 데이터와 레이블을 예시 데이터로 대체해야 합니다.
# URL 문자열을 벡터화하고, 레이블을 정수로 변환하는 코드도 추가해야 합니다.

# 모델 훈련
for epoch in range(num_epochs):
    outputs = model(train_data)  # train_data는 URL 데이터를 숫자로 벡터화한 것
    optimizer.zero_grad()
    loss = criterion(outputs, train_labels)  # train_labels는 URL 유형에 해당하는 정수
    loss.backward()
    optimizer.step()
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')

# 모델 평가
model.eval()
with torch.no_grad():
    test_outputs = model(test_data)  # test_data는 평가용 URL 데이터
    _, predicted = torch.max(test_outputs, 1)
    accuracy = (predicted == test_labels).sum().item() / test_labels.size(0)
    print(f'Accuracy: {accuracy}')

# 예측 결과를 사용하여 URL 유형을 문자열로 변환하는 코드를 추가해야 합니다.
```

---

 LSTM과  GRU 모델 비교 사용
 
---