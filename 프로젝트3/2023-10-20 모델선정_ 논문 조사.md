딥러닝 모델 선정과정


**자연어 처리 (Natural Language Processing, NLP)**: RNN 및 그 변형은 텍스트 데이터와 언어 모델링을 위해 널리 사용되는 기술 중 하나입니다. 자연어 처리는 RNN의 주요 응용 분야 중 하나입니다.

**시계열 데이터 분석**: 시계열 데이터 분석은 RNN을 포함한 순환 신경망을 사용하여 주가 예측, 날씨 예측 및 시계열 데이터 모델링과 같은 작업을 수행하는 데 사용됩니다.


순환신경망 종류 

RNN(Recurrent Neural Network)은 시계열 데이터 및 순차 데이터 처리를 위한 신경망 아키텍처 중 하나입니다. 
그러나 RNN 이외에도 다양한 다른 신경망 아키텍처 및 관련 개념이 존재합니다. 
이러한 개념 중 일부는 다음과 같습니다:

1. **LSTM (Long Short-Term Memory)**: LSTM은 RNN의 변형 중 하나로, 단기 및 장기 메모리를 효과적으로 관리하여 장기적인 의존성을 학습할 수 있도록 설계되었습니다. 주로 시계열 데이터 및 자연어 처리에 사용됩니다.

2. **GRU (Gated Recurrent Unit)**: GRU도 LSTM과 유사한 RNN 변형으로, LSTM보다 간단한 구조를 가지면서도 장기 의존성을 학습할 수 있습니다. 주로 자연어 처리와 음성 처리에서 사용됩니다.

3. **CNN (Convolutional Neural Network)**: CNN은 주로 이미지 처리에 사용되며, 컨볼루션 레이어와 풀링 레이어를 사용하여 특징을 추출하고 분류 작업에 적합한 아키텍처입니다.

4. **Autoencoder**: 오토인코더는 비지도 학습 모델로, 입력 데이터를 압축하고 복원함으로써 데이터 표현을 학습합니다. 주로 차원 축소 및 노이즈 제거에 사용됩니다.

5. **GAN (Generative Adversarial Network)**: GAN은 생성 모델로, 생성자와 판별자라는 두 개의 네트워크가 적대적인 학습을 통해 데이터를 생성하고 판별하는 방식으로 작동합니다.

6. **Transformer**: Transformer는 자연어 처리 작업에서 주로 사용되는 모델 아키텍처로, 어텐션 메커니즘을 기반으로 문장을 처리합니다. 대표적으로 BERT, GPT, 및 트랜스포머 기반 모델이 있습니다.

7. **시계열 분석**: 시계열 분석은 통계적인 방법을 사용하여 시계열 데이터의 특성을 분석하고 예측 모델을 개발하는 과정을 의미합니다. ARIMA, Prophet 등의 방법이 사용됩니다.

8. **강화 학습 (Reinforcement Learning)**: 강화 학습은 에이전트가 환경과 상호작용하며 보상을 최대화하는 방법을 학습하는 머신 러닝 패러다임입니다.

9. **VAE (Variational Autoencoder)**: VAE는 오토인코더의 확률적 변형으로, 데이터의 확률적 표현을 학습하고 생성에 사용됩니다.

10. **PCA (Principal Component Analysis)**: PCA는 차원 축소를 위해 사용되며 데이터의 주성분을 추출하여 차원을 축소합니다.

이러한 다양한 신경망 아키텍처와 머신 러닝 개념은 다른 유형의 데이터 및 작업에 대한 효과적인 모델링을 지원하며, 각각 특정한 응용 분야와 문제에 맞게 선택됩니다.

---



**GRU** : 순환신경망(RNN) 아키텍쳐의 일종 GRU는 LSTM과 유사하지만 조금 더 간결한 구조임
		학습과 예측 속도에서 앞서며 URL구조가 복잡하지 않기 때문에 LSTM보다는 GRU 선택이 맞을듯
	
[[Transformer]]
- 셀프 어텐션 메커니즘을 활용하기 때문에 입력시퀀스 (url 전체를 넣어도?) 각 요소에 다른 요소와의 상호 관계를 따져 가중치 부여
- 스택된 어텐션 레이어 다음 레이어로 정보를 전달  (LSTM) 의 역할과 비스무리)
- 멀티헤드 어텐션 서로 다른 어텐션 가중치 결과를 계산하고, 이러한 다양한 관점을 조합 (2차 조합)
Transformer의 강력한 능력은 대규모 데이터와 충분한 계산 리소스를 활용할 때 더욱 빛을 발합니다.

[[BERT]]
bert 모델은 Transformer 신경망 아키텍쳐 기반
텍스트 분류, 텍스트 생성, 질문 응답 등 다양한 작업에 활용 가능



토큰화를 크게 잡기?
활성화 함수는 tanh 이나 relu 씀 기본값은  tanh



---
---


데이터

---

학습데이터 겁증데이터 테스트데이터

로 나눈다



---

층 구성  

모델구성 
tf.keras.Sequential 

입력층
input_shape = (2, 0 ) 두번째 층부터는 자동
중간층

출력층


평균 제곱 오차 회귀
loss = 'mse'
이항
'binary_crossentropy'
컴파일에서 다항은
'categorical_crossentropy'

컴파일에서는 
옵티마이저  adam
손실함수 categorical_crossentropy
평가지표 acc

---

컴파일

학습

평가

- evaluate()


---


Whitelist./Blakclist
Rule-based
Search Volume

**Whitelist./Blakclist**기반 악성 URL
탐지 방식은 리스트 생성자가 미리 안전하거나 위협이 되는것에 대하여
등록하여 차단하는 것으로 신규위협에 취약하며, 리스트를 생성하는 인력
에 의하여 탐지 기준이 정해지기 때문에 정확성의 편차가 떨어진다.

Rule-based기반 악성 URL 탐지 방식은 공격 시도 과정에서의 일정한 규칙을 찾아내고, 공격시도를 탐지하여 차단하는 기술로 기존 공격자의 패턴이 있는 공격에 대하여 탐지는 가능하지만, 해당 규칙을 벗어난 변종 공격은 탐지하지 못한다.


. Search Volume기반 악성 URL탐지 방식은 구글,
네이버 등 포털사이트의 검색엔진을 이용하여 해당 사이트의 URL을 검색하여 포털에서의 URL 검색 양을 확인한다.
비정상적인 URL은 실제로 서비스되지 않고, 검색하는 사람이 적은 특징을 노린 기법이다. 하지만 이 기법의 경우 신규 사이트나 비인기 사이트에 대한 탐지를 하는데 좋지 못한 결과를 보여준다.



주어진 데이터 간의 복잡성 을 줄이고 패턴을 보다 잘 나타내기 위한 Feature Engineering 기법으로 텍스트 마이닝 기법중 하나인 TF-IDF(Term Frequency - Inverse Document Frequency) 가 중치를 적용하여 가공하여 악성코드 분석에 활용하
변환된 벡터를 기반으로 Machine Learning의 DNN(Deep Neural Network)과 k-NN(k-Nearest Neighbor) 알고리즘을 이용해 악성코드 분석을 진행하고자 한다.


알려지지 않은 악성코드의 경우 패턴이 존 재하지 않을 확률이 매우 높다.

이에 해당하는 패턴을 생 성하기 위해서는 시간이 소요되며 즉각적인 탐지에 어려 움이 존재한다



바이러스토탈은 구글의 자회사로 편입된 회사이며, 약 69개 안티바이러스 회사들과 제휴하여 악성코드 정보를 공유하고 있으며, 특히 전 세계 일반 사용자들이 업로드한 악성코드, URL및 PCAP등을 약 69개 안티바이러스 회사들의 엔진으로 검사하고 해당 결과를 제공하는 클라우드 서비스이다. 바이러스토탈에서는 동일한 과정을 자동화된 서비스로 제공하기 위하여 API를 제공하는 데, 오픈 API와 유료 API로 구분된다. 바이러스토탈 사이트는 사용자가 수동 또는 오픈 API를 통해 업로드 한 악성파일에 대하여 여러 개의 백신 엔진으로 검사한 결과를 투명하게 제공한다. 

딥 러닝에서 사용하는 멀티 레이어 퍼셉트론을 사용하는 경우, 입력 레이어와 출력 레이어 사이에 은닉 레이어가 생성되며 보안 분석가는 은닉 레이어에 대해서는 직관적으로 이해할 수 없다. 

이러한 문제가 존재하지 않는 거의 유일한 분류 알고리즘은 결정 트리 알고리즘이다


---

# 플라스크 코드 10/20
```python
from flask import Flask, request, jsonify  
from flask_cors import CORS  
import cx_Oracle  
import numpy as np  
import os  
from tensorflow.keras.models import load_model  
from tensorflow.keras.preprocessing.text import Tokenizer  
from tensorflow.keras.preprocessing.sequence import pad_sequences  
from sklearn.preprocessing import LabelEncoder  
  
## 사용 IDE : Pycham## 필요 라이브러리 : Flask, cx_Oracle, TensorFlow, NumPy, scikit-learn  
                                                                                                                        # 오라클 클라이언트 라이브러리 초기화  
cx_Oracle.init_oracle_client(lib_dir=r"C:\oraclexe\app\instantclient_19_20")                                            # 컴퓨터에 오라클이 두개라서 필요한 코드라 삭제해도됨  
                                                                                                                        # 주피터노트북에서 실행시 불필요한 것으로 앎  
app = Flask(__name__)  
CORS(app)  
  
username = 'DCLTEST'  
password = '12345'  
dsn = 'xe'                                                                                                              # 실제 TNS 이름으로 변경  
  
model_file_path = "best_model_test.h5"                                                                                  # 모델 파일 경로  
  
@app.route('/test', methods=['GET', 'POST'])  
def hello_world():  
    data = request.get_json()                                                                                           # get방식 request 키:밸류 형식에서 url데이터를 변수지정  
    url = data.get('url')  
  
    if url is None :  
        return jsonify({'error_1': 'URL 정보를 전달 받지 못함.'})  
    else :  
        print('URL 정보를 전달 받음')  
    if not os.path.isfile(model_file_path):  
        print(f"error_2 :'{model_file_path}' 모델을 찾지 못함. Line-39")  
        return jsonify({'error_2': '모델 로드 오류'})  
    else:                                                                                                               # 모델이 잘 불러와진다면 IF ELSE 삭제  
        if url is not None :                                                                                            # URL이 불러와졌다면 진입  
            print('모델 로드완료')  
            try :                                                                                                       # DB url 존재 여부 조회 시도  
                print('오라클 연결시도')  
                connection = cx_Oracle.connect(username, password, dsn)                                                 # Oracle 데이터베이스에 연결  
                cursor = connection.cursor()  
                # SELECT SQL 쿼리  
                sql_query_select = f"""                                                                                           
                    SELECT MLCS_STATUS , URL_NAME   
                    FROM T_URL  
                    WHERE URL_NAME = '{url}'  
                """                cursor.execute(sql_query_select)                                                                        # SELECT 쿼리 실행  
                result = cursor.fetchone()                                                                              # 결과를 가져오기  
  
                cursor.close()                                                                                          # 커서와 연결 닫기  
                connection.close()  
                if result:                                                                                              # DB에 url 존재시 조회 및 조회수 증가  
                    pre_type = result[0]  
                    url_name = result[1]  
                    connection = cx_Oracle.connect(username, password, dsn)  
                    cursor = connection.cursor()  
                    sql_query_cnt = f"""  
                        UPDATE T_URL                        SET URL_CNT = URL_CNT + 1                        WHERE URL_NAME = '{url}'  
                    """                    try:                                                                                                # URL_CNT 증가를 위한 UPDATE 쿼리 실행  
                        cursor.execute(sql_query_cnt)  
                        connection.commit()  
                    except cx_Oracle.Error as error:                                                                    # 조회수 업데이트 실패시 진입  
                        print('Line-72 UPDATE_조회수_오류:', error)  
                    finally:  
                        cursor.close()  
                        connection.close()  
                        return jsonify({'url' : url_name , 'MLCS_STATUS' : pre_type})                                   # 기존 DB                else:                                                                                                   # 신규 URL 일시 진입  
  
                    model = load_model(model_file_path)                                                                 # 모델 로딩  
  
                    tokenizer = Tokenizer(num_words=10000)                                                              # Tokenizer 인스턴스 생성  
  
                    url_sequences = tokenizer.texts_to_sequences([url])                                                 # URL 텍스트를 시퀀스로 변환  
                    url_sequences = pad_sequences(url_sequences, maxlen=240)  
  
                    predictions = model.predict(url_sequences)                                                          # 예측  
  
                    labels = ["phishing", "benign", "defacement", "malware"]                                            # 예측된 레이블 출력  
                                                                                                                        # 레이블 정의  
                    label_encoder = LabelEncoder()                                                                      # LabelEncoder 인스턴스 생성  
                    label_encoder.fit(labels)                                                                           # 레이블에 맞게 학습  
  
                    predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))  
  
                    MLCS_STATUS = predicted_labels[0]  
                    if predicted_labels[0] == 'benign' :                                                                # 안전함으로 판단시 쿼리  
                        sql_query_safe = f"""  
                            INSERT INTO T_URL (URL_NAME, MLCS_STATUS, URL_YN, URL_CNT, URL_DATE)                            VALUES ('{url}', '{MLCS_STATUS}', 'Y', 1, SYSDATE)  
                        """                        connection = cx_Oracle.connect(username, password, dsn)  
                        cursor = connection.cursor()  
  
                        cursor.execute(sql_query_safe)  
  
                        connection.commit()  
  
                        cursor.close()  
                        connection.close()  
                        print(url, MLCS_STATUS)  
                    else:                                                                                               # 안전함 외로 판단시 쿼리  
                        sql_query_unsafe = f"""  
                            INSERT INTO T_URL (URL_NAME, MLCS_STATUS, URL_YN, URL_CNT, URL_DATE)                            VALUES ('{url}', '{MLCS_STATUS}', 'Y', 1, SYSDATE)  
                        """                        connection = cx_Oracle.connect(username, password, dsn)  
                        cursor = connection.cursor()  
  
                        cursor.execute(sql_query_unsafe)  
                        connection.commit()  
  
                        cursor.**close**()  
                        connection.close()  
                        print(url, MLCS_STATUS)  
                    return jsonify({'url' : url , 'MLCS_STATUS' : MLCS_STATUS })  
            except cx_Oracle.Error as error:                                                                            # 셀렉트 오류시 진입  
                return jsonify({'error_3-1': '오라클 셀렉트 문 오류'})  
        else :  
            return jsonify({'error Line- 138': {'url DB에 없음'}})  
  
if __name__ == '__main__':  
    #app.run()  
    # host에 본인 아이피 주소 넣으세요  
    app.run(host='0.0.0.0', port=5000, debug=True)  
    # http://172.30.1.57:5000/ 로 접속
```



---


---